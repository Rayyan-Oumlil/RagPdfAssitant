# ğŸ§  RAG PDF Assistant

A local AI assistant that lets you upload **PDF files** and ask **questions** about them using **RAG (Retrieval-Augmented Generation)**. It runs **fully offline** using a local LLM like Mistral via [Ollama](https://ollama.com), and uses `FAISS` + `sentence-transformers` for semantic search.

> Built with FastAPI, PyMuPDF, FAISS, and Mistral LLM.

---

## ğŸ“¦ Features

- ğŸ” Extracts text from PDF files
- ğŸ§  Splits and embeds document chunks
- ğŸ” Retrieves relevant content using vector search (FAISS)
- ğŸ¤– Answers questions using a local LLM (Mistral)
- ğŸ’¾ Works fully offline (no OpenAI API needed)
- ğŸ”§ Easy to extend with Streamlit, React, or Docker

---

## ğŸš€ Tech Stack

| Category | Tools Used |
|----------|------------|
| Backend  | **FastAPI**, Python |
| AI / NLP | **Mistral (via Ollama)**, SentenceTransformers |
| Embeddings | `all-MiniLM-L6-v2` |
| Vector Search | **FAISS** |
| File Parsing | **PyMuPDF** |
| Deployment | Localhost, Docker (optional) |
| UI (Optional) | Streamlit or React |

---

## ğŸ“ Project Structure

rag-assistant/
â”œâ”€â”€ backend/ # FastAPI backend
â”‚ â”œâ”€â”€ main.py # API endpoints
â”‚ â”œâ”€â”€ rag.py # RAG logic (embedding + retrieval)
â”‚ â””â”€â”€ utils.py # PDF parsing + chunking
â”œâ”€â”€ data/ # Uploaded files & FAISS index
â”œâ”€â”€ models/ # Optional LLM/config files
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .gitignore # Ignore cache, env, FAISS index
â””â”€â”€ README.md # You're here!

---

## âš™ï¸ Requirements

- Python 3.10+
- [Ollama](https://ollama.com) (for local LLMs)
- Git, pip

---

## ğŸ§ª Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/Rayyan-Oumlil/RagPdfAssitant.git
cd RagPdfAssitant
