# ğŸ§  RAG PDF Assistant

A local AI assistant that lets you upload **PDF files** and ask **questions** about them using **RAG (Retrieval-Augmented Generation)**. It runs **fully offline** using a local LLM like Mistral via [Ollama](https://ollama.com), and uses `FAISS` + `sentence-transformers` for semantic search.

> Built with FastAPI, PyMuPDF, FAISS, and Mistral LLM.

---

## ğŸ“¦ Features

- ğŸ” Extracts text from PDF files
- ğŸ§  Splits and embeds document chunks
- ğŸ” Retrieves relevant content using vector search (FAISS)
- ğŸ¤– Answers questions using a local LLM (Mistral)
- ğŸ’¾ Works fully offline (no OpenAI API needed)
- ğŸ”§ Easy to extend with Streamlit, React, or Docker

---

## ğŸš€ Tech Stack

| Category | Tools Used |
|----------|------------|
| Backend  | **FastAPI**, Python |
| AI / NLP | **Mistral (via Ollama)**, SentenceTransformers |
| Embeddings | `all-MiniLM-L6-v2` |
| Vector Search | **FAISS** |
| File Parsing | **PyMuPDF** |
| Deployment | Localhost, Docker (optional) |
| UI (Optional) | Streamlit or React |

---

## ğŸ“ Project Structure

